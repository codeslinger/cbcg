---
title: GemStone Systems -- We Solve the Hardest Problems
layout: post
---
<div class="posterous_bookmarklet_entry">
<blockquote class="posterous_medium_quote">A data management platform that dynamically runs across many machines requires—as a foundation—a fast, scalable, fault-tolerant distributed system.  It is well-known, however, that <a href="http://research.sun.com/technical-reports/1994/smli_tr-94-29.pdf" rel="nofollow"><strong>distributed systems have unavoidable tradeoffs</strong></a> <sup><a href="#fn3" rel="nofollow">3</a></sup> and <a href="#fn4" rel="nofollow"><strong>notoriously complex implementation challenges</strong></a> <sup><a href="#fn4" rel="nofollow">4</a></sup>. Introduced at <a href="http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf" rel="nofollow"><span class="caps">PODC</span> 2000 by Eric Brewer</a> <sup><a href="#fn5" rel="nofollow">5</a></sup> and formally <a href="#fn6" rel="nofollow">proven by Seth Gilbert and Nancy Lynch in 2002</a> <sup><a href="#fn6" rel="nofollow">6</a></sup>, the <strong><span class="caps">CAP</span> Theorem</strong>, in particular, stipulates that it is impossible for a distributed system to be simultaneously: <strong>Consistent, Available, and Partition-Tolerant. At any given time, only two of these three desirable properties can be achieved</strong>. Hence when building distributed systems, design tradeoffs must be made.</blockquote></p><p><div class="posterous_quote_citation">via <a href="http://www.gemstone.com/hardest-problems" rel="nofollow">gemstone.com</a>
</div>
    <p>A bit fluffy, but more technical than the average whitepaper. It makes me wonder what their biggest deployments look like.</p>
</div>
